{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemandPredictionPythonModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brontominds/bounce_demand/blob/v0.01/DemandPredictionPythonModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-utKQafzbKAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt  # For plotting graphs \n",
        "from datetime import datetime    # To access datetime \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.optimizers import Adam,SGD,RMSprop,Adagrad\n",
        "\n",
        "\n",
        "\n",
        "#Add date time specific columns to the dataframe\n",
        "def datetime(df):\n",
        "  from datetime import datetime\n",
        "  df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "  df['year'] = df['datetime'].dt.year\n",
        "  df['month']=df['datetime'].dt.month\n",
        "  df['day'] = df['datetime'].dt.day \n",
        "  df['hour'] = df['datetime'].dt.hour\n",
        "  df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "  return df\n",
        "\n",
        "#Normalize a column of dataframe and return mean and sd\n",
        "def normalize(df,feature_name):\n",
        "  mean_value = df[feature_name].mean()\n",
        "  std_value = df[feature_name].std()\n",
        "  df[feature_name] = (df[feature_name] - mean_value) / std_value        \n",
        "  return (df, mean_value, std_value)\n",
        "\n",
        "\n",
        "#One hot encode data\n",
        "def dummy_data(data, columns):\n",
        "    for column in columns:\n",
        "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
        "        data = data.drop(column, axis=1)\n",
        "    return data\n",
        "\n",
        "#Drop Redundant Columns\n",
        "def drop_redundantcolumns(data):\n",
        "  return (data.drop([\"casual\",\"registered\"], axis=1))  \n",
        "\n",
        "#Create target variable and convert features dataframe to a numpy array\n",
        "def create_targetvariable(data, fraction=0.2):\n",
        "    data_y = data[\"count\"]\n",
        "    data_x = data.drop([\"count\"], axis=1)\n",
        "    return data_x.values, data_y\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0YEUZ1IUKSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "def plotOutliers(df):\n",
        "  plt.figure(1)\n",
        "  plt.subplot(121)\n",
        "  sns.distplot(df); \n",
        "  plt.subplot(122)\n",
        "  df.plot.box(figsize=(16,5)) \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Zl-EG3cBUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read Training Data\n",
        "data=pd.read_csv(\"train.csv\")\n",
        "data_original=data\n",
        "\n",
        "#Add new features of date time\n",
        "data=datetime(data)\n",
        "data=data.drop('datetime',axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv_OBBjFVEE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot graphs if required\n",
        "#plotOutliers(data['atemp'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWRVTrqqU9uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform Data\n",
        "#Normalize weather data\n",
        "data, mean_temp, sd_temp=normalize(data,[\"temp\"])\n",
        "data,mean_atemp,sd_atemp=normalize(data,[\"atemp\"])\n",
        "data,mean_humidity,sd_humidity=normalize(data,[\"humidity\"])\n",
        "data,mean_windspeed,sd_windspeed=normalize(data,[\"windspeed\"])\n",
        "\n",
        "#One hot-encode categorical data\n",
        "data = dummy_data(data, [\"season\",\"weather\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n",
        "#TODO: Check which all features require hot encoding, and which work better without hot encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYFTtiuCUfkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "12642de4-3adf-4b98-de91-4b9ee92ddc6c"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6UAAAFACAYAAABEN9peAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awuxCbq6dxMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shuffle data and split into training+validation, and testing\n",
        "#Training and Validation data kept together as Keras will do the auto split\n",
        "data=shuffle(data,random_state=1) #Seed=1 applied for ability to repeat same tests with parameters tuning\n",
        "\n",
        "testDataSplit=0 #0.3 means 30% data will be taken out for test and remaining for training+validation\n",
        "nrows = len(data)\n",
        "training_validation_rows = int(nrows*(1-testDataSplit))\n",
        "training_validation_data=data[0:training_validation_rows-1]\n",
        "test_data=data[training_validation_rows:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6fL547YeY9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop casual and registered users columns\n",
        "training_validation_data = drop_redundantcolumns(training_validation_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "data_x, data_y = create_targetvariable(training_validation_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKDHHP0wfagY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate NN Sequential Model\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = data_x.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='softplus'))\n",
        "\n",
        "#Define optimizer\n",
        "adam = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer=adam, metrics=['mean_absolute_error','mean_squared_error'])\n",
        "#NN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqrlKX-geLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define callbacks for model training\n",
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose =1, save_best_only = True, mode ='auto')\n",
        "early_stop=EarlyStopping(monitor='val_loss',patience=10)\n",
        "callbacks_list = [checkpoint,early_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfpV__-fal1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define plot function to show training and validation losses\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPQpyEsPg2Gu",
        "colab_type": "code",
        "outputId": "9903dc83-5457-4fa4-dcad-ed059c335d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#TRAIN MODEL\n",
        "history=NN_model.fit(data_x, data_y, epochs=1000, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8708 samples, validate on 2177 samples\n",
            "Epoch 1/1000\n",
            "8708/8708 [==============================] - 2s 214us/step - loss: 2.1842 - mean_absolute_error: 143.6277 - mean_squared_error: 41780.7941 - val_loss: 2.0549 - val_mean_absolute_error: 138.0659 - val_mean_squared_error: 37253.7161\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.05492, saving model to Weights-001--2.05492.hdf5\n",
            "Epoch 2/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 1.9091 - mean_absolute_error: 139.7101 - mean_squared_error: 40606.2521 - val_loss: 1.4221 - val_mean_absolute_error: 122.5117 - val_mean_squared_error: 33679.4904\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.05492 to 1.42214, saving model to Weights-002--1.42214.hdf5\n",
            "Epoch 3/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 1.1057 - mean_absolute_error: 111.1046 - mean_squared_error: 28079.4938 - val_loss: 0.9438 - val_mean_absolute_error: 105.9648 - val_mean_squared_error: 26933.0099\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.42214 to 0.94380, saving model to Weights-003--0.94380.hdf5\n",
            "Epoch 4/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 1.0192 - mean_absolute_error: 108.6709 - mean_squared_error: 27068.8096 - val_loss: 0.9207 - val_mean_absolute_error: 103.6632 - val_mean_squared_error: 24887.9562\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.94380 to 0.92069, saving model to Weights-004--0.92069.hdf5\n",
            "Epoch 5/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 1.0195 - mean_absolute_error: 109.0211 - mean_squared_error: 27364.7977 - val_loss: 1.1777 - val_mean_absolute_error: 106.5288 - val_mean_squared_error: 24166.5539\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.92069\n",
            "Epoch 6/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.9187 - mean_absolute_error: 105.2227 - mean_squared_error: 26147.3012 - val_loss: 0.7905 - val_mean_absolute_error: 94.9605 - val_mean_squared_error: 20690.8858\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.92069 to 0.79050, saving model to Weights-006--0.79050.hdf5\n",
            "Epoch 7/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.7633 - mean_absolute_error: 99.0634 - mean_squared_error: 23738.2430 - val_loss: 0.5741 - val_mean_absolute_error: 86.9606 - val_mean_squared_error: 16917.8197\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.79050 to 0.57415, saving model to Weights-007--0.57415.hdf5\n",
            "Epoch 8/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.5755 - mean_absolute_error: 90.9021 - mean_squared_error: 20660.6337 - val_loss: 0.5269 - val_mean_absolute_error: 82.9138 - val_mean_squared_error: 17287.1233\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57415 to 0.52695, saving model to Weights-008--0.52695.hdf5\n",
            "Epoch 9/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.4689 - mean_absolute_error: 85.1088 - mean_squared_error: 18400.0841 - val_loss: 0.7452 - val_mean_absolute_error: 88.6774 - val_mean_squared_error: 19524.9663\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.52695\n",
            "Epoch 10/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.4301 - mean_absolute_error: 82.7380 - mean_squared_error: 17587.2220 - val_loss: 0.3827 - val_mean_absolute_error: 78.8321 - val_mean_squared_error: 15893.5629\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.52695 to 0.38269, saving model to Weights-010--0.38269.hdf5\n",
            "Epoch 11/1000\n",
            "8708/8708 [==============================] - 1s 130us/step - loss: 0.4493 - mean_absolute_error: 86.1941 - mean_squared_error: 18940.2219 - val_loss: 0.3861 - val_mean_absolute_error: 78.5947 - val_mean_squared_error: 15798.1566\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.38269\n",
            "Epoch 12/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3879 - mean_absolute_error: 80.9688 - mean_squared_error: 16971.1547 - val_loss: 0.4620 - val_mean_absolute_error: 80.9492 - val_mean_squared_error: 14281.4611\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.38269\n",
            "Epoch 13/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.3697 - mean_absolute_error: 79.3628 - mean_squared_error: 16218.0557 - val_loss: 0.5437 - val_mean_absolute_error: 104.3604 - val_mean_squared_error: 20150.7058\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.38269\n",
            "Epoch 14/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.4153 - mean_absolute_error: 84.2429 - mean_squared_error: 18362.1842 - val_loss: 0.3242 - val_mean_absolute_error: 76.3519 - val_mean_squared_error: 14417.3557\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.38269 to 0.32424, saving model to Weights-014--0.32424.hdf5\n",
            "Epoch 15/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.3556 - mean_absolute_error: 78.3546 - mean_squared_error: 15957.3133 - val_loss: 0.4099 - val_mean_absolute_error: 79.5643 - val_mean_squared_error: 16897.1777\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.32424\n",
            "Epoch 16/1000\n",
            "8708/8708 [==============================] - 1s 133us/step - loss: 0.3592 - mean_absolute_error: 77.7360 - mean_squared_error: 15660.9378 - val_loss: 0.3005 - val_mean_absolute_error: 72.1001 - val_mean_squared_error: 13657.8697\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.32424 to 0.30052, saving model to Weights-016--0.30052.hdf5\n",
            "Epoch 17/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.3249 - mean_absolute_error: 75.0128 - mean_squared_error: 14772.7169 - val_loss: 0.3559 - val_mean_absolute_error: 72.3830 - val_mean_squared_error: 13021.3005\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.30052\n",
            "Epoch 18/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.3409 - mean_absolute_error: 75.4050 - mean_squared_error: 14671.9870 - val_loss: 0.3078 - val_mean_absolute_error: 72.4348 - val_mean_squared_error: 14279.5549\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.30052\n",
            "Epoch 19/1000\n",
            "8708/8708 [==============================] - 1s 122us/step - loss: 0.3227 - mean_absolute_error: 73.6196 - mean_squared_error: 14132.8877 - val_loss: 0.3093 - val_mean_absolute_error: 69.3279 - val_mean_squared_error: 12558.3929\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.30052\n",
            "Epoch 20/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3056 - mean_absolute_error: 71.8590 - mean_squared_error: 13436.5668 - val_loss: 0.2974 - val_mean_absolute_error: 66.9669 - val_mean_squared_error: 12318.3263\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.30052 to 0.29738, saving model to Weights-020--0.29738.hdf5\n",
            "Epoch 21/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3201 - mean_absolute_error: 71.9497 - mean_squared_error: 13465.3213 - val_loss: 0.3058 - val_mean_absolute_error: 70.7824 - val_mean_squared_error: 13393.3537\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.29738\n",
            "Epoch 22/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2825 - mean_absolute_error: 67.7581 - mean_squared_error: 11971.9648 - val_loss: 0.2786 - val_mean_absolute_error: 65.9226 - val_mean_squared_error: 10285.3899\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.29738 to 0.27856, saving model to Weights-022--0.27856.hdf5\n",
            "Epoch 23/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.3312 - mean_absolute_error: 70.7821 - mean_squared_error: 13011.4989 - val_loss: 0.4127 - val_mean_absolute_error: 76.3887 - val_mean_squared_error: 13872.8707\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.27856\n",
            "Epoch 24/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2727 - mean_absolute_error: 66.1412 - mean_squared_error: 11236.5169 - val_loss: 0.3997 - val_mean_absolute_error: 68.9648 - val_mean_squared_error: 11676.0729\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.27856\n",
            "Epoch 25/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2798 - mean_absolute_error: 65.9492 - mean_squared_error: 11173.8672 - val_loss: 0.2354 - val_mean_absolute_error: 60.3395 - val_mean_squared_error: 10114.4095\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.27856 to 0.23537, saving model to Weights-025--0.23537.hdf5\n",
            "Epoch 26/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2506 - mean_absolute_error: 62.9837 - mean_squared_error: 10216.9984 - val_loss: 0.3360 - val_mean_absolute_error: 65.6248 - val_mean_squared_error: 10609.9380\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.23537\n",
            "Epoch 27/1000\n",
            "8708/8708 [==============================] - 1s 137us/step - loss: 0.2974 - mean_absolute_error: 66.5413 - mean_squared_error: 11433.7273 - val_loss: 0.2327 - val_mean_absolute_error: 59.4020 - val_mean_squared_error: 8998.9497\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.23537 to 0.23275, saving model to Weights-027--0.23275.hdf5\n",
            "Epoch 28/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2299 - mean_absolute_error: 59.9400 - mean_squared_error: 9156.6935 - val_loss: 0.2553 - val_mean_absolute_error: 57.5921 - val_mean_squared_error: 8125.3358\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.23275\n",
            "Epoch 29/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2408 - mean_absolute_error: 60.3312 - mean_squared_error: 9212.0522 - val_loss: 0.2388 - val_mean_absolute_error: 58.6634 - val_mean_squared_error: 8531.8358\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.23275\n",
            "Epoch 30/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2390 - mean_absolute_error: 59.6463 - mean_squared_error: 8943.6158 - val_loss: 0.2280 - val_mean_absolute_error: 58.0987 - val_mean_squared_error: 8583.1227\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.23275 to 0.22803, saving model to Weights-030--0.22803.hdf5\n",
            "Epoch 31/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2415 - mean_absolute_error: 61.1065 - mean_squared_error: 9416.1221 - val_loss: 0.3230 - val_mean_absolute_error: 62.4934 - val_mean_squared_error: 9077.5572\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.22803\n",
            "Epoch 32/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 0.2332 - mean_absolute_error: 59.5337 - mean_squared_error: 8850.0561 - val_loss: 0.2114 - val_mean_absolute_error: 54.4194 - val_mean_squared_error: 7502.2957\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.22803 to 0.21138, saving model to Weights-032--0.21138.hdf5\n",
            "Epoch 33/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2409 - mean_absolute_error: 60.6202 - mean_squared_error: 9109.9508 - val_loss: 0.3099 - val_mean_absolute_error: 62.6497 - val_mean_squared_error: 9953.7802\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.21138\n",
            "Epoch 34/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2383 - mean_absolute_error: 59.9274 - mean_squared_error: 8896.6274 - val_loss: 0.2315 - val_mean_absolute_error: 60.5266 - val_mean_squared_error: 9943.8817\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.21138\n",
            "Epoch 35/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2262 - mean_absolute_error: 58.5496 - mean_squared_error: 8533.4238 - val_loss: 0.2359 - val_mean_absolute_error: 57.3609 - val_mean_squared_error: 8402.4298\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.21138\n",
            "Epoch 36/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2279 - mean_absolute_error: 58.8812 - mean_squared_error: 8639.2567 - val_loss: 0.2610 - val_mean_absolute_error: 61.2417 - val_mean_squared_error: 9330.5366\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.21138\n",
            "Epoch 37/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2395 - mean_absolute_error: 59.4465 - mean_squared_error: 8729.3288 - val_loss: 0.2956 - val_mean_absolute_error: 56.8045 - val_mean_squared_error: 7023.7385\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.21138\n",
            "Epoch 38/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2378 - mean_absolute_error: 59.0853 - mean_squared_error: 8575.7801 - val_loss: 0.2225 - val_mean_absolute_error: 54.7073 - val_mean_squared_error: 7455.8425\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.21138\n",
            "Epoch 39/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2092 - mean_absolute_error: 56.2582 - mean_squared_error: 7812.1188 - val_loss: 0.2187 - val_mean_absolute_error: 52.0015 - val_mean_squared_error: 6267.4166\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.21138\n",
            "Epoch 40/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.2247 - mean_absolute_error: 57.9082 - mean_squared_error: 8370.2837 - val_loss: 0.2578 - val_mean_absolute_error: 58.1293 - val_mean_squared_error: 8658.3333\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.21138\n",
            "Epoch 41/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2102 - mean_absolute_error: 56.6967 - mean_squared_error: 7947.1307 - val_loss: 0.2036 - val_mean_absolute_error: 51.8818 - val_mean_squared_error: 6308.6434\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.21138 to 0.20365, saving model to Weights-041--0.20365.hdf5\n",
            "Epoch 42/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2172 - mean_absolute_error: 57.4528 - mean_squared_error: 8050.2778 - val_loss: 0.2400 - val_mean_absolute_error: 57.5194 - val_mean_squared_error: 8134.0625\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.20365\n",
            "Epoch 43/1000\n",
            "8708/8708 [==============================] - 1s 130us/step - loss: 0.2138 - mean_absolute_error: 56.1136 - mean_squared_error: 7692.6305 - val_loss: 0.2200 - val_mean_absolute_error: 54.2354 - val_mean_squared_error: 6653.2693\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.20365\n",
            "Epoch 44/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2185 - mean_absolute_error: 57.4614 - mean_squared_error: 8022.6429 - val_loss: 0.2041 - val_mean_absolute_error: 53.3689 - val_mean_squared_error: 7371.4663\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.20365\n",
            "Epoch 45/1000\n",
            "8708/8708 [==============================] - 1s 133us/step - loss: 0.2178 - mean_absolute_error: 57.0232 - mean_squared_error: 8001.4593 - val_loss: 0.2230 - val_mean_absolute_error: 56.9553 - val_mean_squared_error: 8426.2739\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.20365\n",
            "Epoch 46/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.2547 - mean_absolute_error: 59.7403 - mean_squared_error: 8805.1366 - val_loss: 0.2048 - val_mean_absolute_error: 53.3405 - val_mean_squared_error: 7056.4849\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.20365\n",
            "Epoch 47/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.2057 - mean_absolute_error: 55.5605 - mean_squared_error: 7533.5450 - val_loss: 0.2016 - val_mean_absolute_error: 51.7192 - val_mean_squared_error: 6012.5996\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.20365 to 0.20156, saving model to Weights-047--0.20156.hdf5\n",
            "Epoch 48/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2093 - mean_absolute_error: 55.8160 - mean_squared_error: 7505.1147 - val_loss: 0.2124 - val_mean_absolute_error: 51.4350 - val_mean_squared_error: 6046.0932\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.20156\n",
            "Epoch 49/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.1994 - mean_absolute_error: 54.9800 - mean_squared_error: 7353.6716 - val_loss: 0.2086 - val_mean_absolute_error: 52.1111 - val_mean_squared_error: 6386.9745\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.20156\n",
            "Epoch 50/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2121 - mean_absolute_error: 56.2182 - mean_squared_error: 7765.1363 - val_loss: 0.2566 - val_mean_absolute_error: 54.5926 - val_mean_squared_error: 6890.7903\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.20156\n",
            "Epoch 51/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2117 - mean_absolute_error: 55.8756 - mean_squared_error: 7606.9326 - val_loss: 0.2272 - val_mean_absolute_error: 57.9149 - val_mean_squared_error: 7617.3545\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.20156\n",
            "Epoch 52/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 0.2278 - mean_absolute_error: 57.4728 - mean_squared_error: 8092.2990 - val_loss: 0.4625 - val_mean_absolute_error: 68.8491 - val_mean_squared_error: 11559.5232\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20156\n",
            "Epoch 53/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2172 - mean_absolute_error: 56.0883 - mean_squared_error: 7571.0692 - val_loss: 0.2168 - val_mean_absolute_error: 53.7451 - val_mean_squared_error: 7112.8999\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.20156\n",
            "Epoch 54/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.2099 - mean_absolute_error: 55.4914 - mean_squared_error: 7495.0230 - val_loss: 0.2225 - val_mean_absolute_error: 55.8354 - val_mean_squared_error: 7388.3490\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20156\n",
            "Epoch 55/1000\n",
            "8708/8708 [==============================] - 1s 140us/step - loss: 0.1997 - mean_absolute_error: 54.8925 - mean_squared_error: 7371.4325 - val_loss: 0.2953 - val_mean_absolute_error: 70.0221 - val_mean_squared_error: 10380.7499\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.20156\n",
            "Epoch 56/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2094 - mean_absolute_error: 55.6973 - mean_squared_error: 7503.5271 - val_loss: 0.2196 - val_mean_absolute_error: 54.8472 - val_mean_squared_error: 7027.5134\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.20156\n",
            "Epoch 57/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2234 - mean_absolute_error: 56.6278 - mean_squared_error: 7887.1674 - val_loss: 0.2556 - val_mean_absolute_error: 59.1789 - val_mean_squared_error: 8274.2631\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yld7jrdxg2J5",
        "colab_type": "code",
        "outputId": "054b1a1f-b5af-43f6-932b-ce03460bb651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Save the trained model to a pickle file\n",
        "import pickle\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(NN_model,'BounceDemandPredictionv001.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BounceDemandPredictionv001.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztRmZBdzhxFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: Export calculated means and sd to a parameters file\n",
        "#STEP 1 DONE\n",
        "# Proceed if you want to evaluate test data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxqXbImhxIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define transformation functions\n",
        "def transform_temp(temp):\n",
        "  return ((temp-mean_temp[0])/sd_temp[0])\n",
        "\n",
        "def transform_atemp(atemp):\n",
        "  return ((atemp-mean_atemp[0])/sd_atemp[0])\n",
        "\n",
        "def transform_humidity(humidity):\n",
        "  return ((humidity-mean_humidity[0])/sd_humidity[0])\n",
        "\n",
        "def transform_windspeed(windspeed):\n",
        "   return ((windspeed-mean_windspeed[0])/sd_windspeed[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMswIHRZirY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate on test data\n",
        "\n",
        "#Drop casual and registered users columns\n",
        "test_data = drop_redundantcolumns(test_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "test_data_x, test_data_y = create_targetvariable(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaG78syOirhK",
        "colab_type": "code",
        "outputId": "80c24db0-0022-4d54-954f-757fe4c17ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scores=NN_model.evaluate(test_data_x,test_data_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2178/2178 [==============================] - 0s 37us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAmOOv7nkJ17",
        "colab_type": "code",
        "outputId": "88821592-e626-4d3c-895e-df5d4ab2c2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test1_loss=scores[0]\n",
        "test1_mae=scores[1]\n",
        "test1_mse=scores[2]\n",
        "\n",
        "test1_mae\n",
        "\n",
        "#Evaluate on Test Data Complete"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.0256134985345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqHHPciAkJ5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L--WIAJFkdhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle submission\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "test_original=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p17NxDxBkp_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform Test Data\n",
        "#Add new features of date time\n",
        "test=datetime(test)\n",
        "test=test.drop('datetime',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MoeVzXUmdrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Normalize weather data\n",
        "test[\"temp\"] = transform_temp(test[\"temp\"])\n",
        "test[\"atemp\"] = transform_temp(test[\"atemp\"])\n",
        "test[\"humidity\"] = transform_temp(test[\"humidity\"])\n",
        "test[\"windspeed\"] = transform_temp(test[\"windspeed\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U7ceaIQolZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#test, mean_temp, sd_temp=normalize(test,[\"temp\"])\n",
        "#test,mean_atemp,sd_atemp=normalize(test,[\"atemp\"])\n",
        "#test,mean_humidity,sd_humidity=normalize(test,[\"humidity\"])\n",
        "#test,mean_windspeed,sd_windspeed=normalize(test,[\"windspeed\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5IW52FNmmIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#One hot-encode categorical data\n",
        "test = dummy_data(test, [\"season\",\"weather\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHI_qAPmO6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction=NN_model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vcmvD2rnLy8",
        "colab_type": "code",
        "outputId": "3246dd38-45ae-424e-df8b-6f5e6fb1ab59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "evaluation=test_original['datetime'].to_frame()\n",
        "evaluation[\"count\"]=prediction\n",
        "evaluation[\"count\"] = evaluation[\"count\"].astype(int)\n",
        "evaluation[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011-01-20 05:00:00</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-01-20 06:00:00</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-01-20 07:00:00</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-01-20 08:00:00</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2011-01-20 09:00:00</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  count\n",
              "0  2011-01-20 00:00:00      6\n",
              "1  2011-01-20 01:00:00      5\n",
              "2  2011-01-20 02:00:00      2\n",
              "3  2011-01-20 03:00:00      1\n",
              "4  2011-01-20 04:00:00      1\n",
              "5  2011-01-20 05:00:00      7\n",
              "6  2011-01-20 06:00:00     50\n",
              "7  2011-01-20 07:00:00    140\n",
              "8  2011-01-20 08:00:00    178\n",
              "9  2011-01-20 09:00:00     58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpa7EWLNngP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation.to_csv(\"submission_anupam.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FZp--YblL2f",
        "colab_type": "code",
        "outputId": "ef88bb3b-2ec2-4a52-cbea-98eff844d0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -1.228358\n",
              "1      -1.228358\n",
              "2      -1.228358\n",
              "3      -1.228358\n",
              "4      -1.228358\n",
              "5      -1.333599\n",
              "6      -1.438841\n",
              "7      -1.438841\n",
              "8      -1.438841\n",
              "9      -1.333599\n",
              "10     -1.228358\n",
              "11     -1.123116\n",
              "12     -1.017874\n",
              "13     -1.123116\n",
              "14     -1.017874\n",
              "15     -0.912633\n",
              "16     -1.017874\n",
              "17     -1.017874\n",
              "18     -1.228358\n",
              "19     -1.228358\n",
              "20     -1.228358\n",
              "21     -1.333599\n",
              "22     -1.333599\n",
              "23     -1.333599\n",
              "24     -1.333599\n",
              "25     -1.333599\n",
              "26     -1.333599\n",
              "27     -1.438841\n",
              "28     -1.438841\n",
              "29     -1.333599\n",
              "          ...   \n",
              "6463   -1.333599\n",
              "6464   -0.807391\n",
              "6465   -1.438841\n",
              "6466   -1.544083\n",
              "6467   -1.544083\n",
              "6468   -1.544083\n",
              "6469   -1.649324\n",
              "6470   -1.649324\n",
              "6471   -1.754566\n",
              "6472   -1.754566\n",
              "6473   -1.859808\n",
              "6474   -1.754566\n",
              "6475   -1.754566\n",
              "6476   -1.754566\n",
              "6477   -1.859808\n",
              "6478   -1.649324\n",
              "6479   -1.544083\n",
              "6480   -1.438841\n",
              "6481   -1.333599\n",
              "6482   -1.228358\n",
              "6483   -1.123116\n",
              "6484   -1.123116\n",
              "6485   -1.228358\n",
              "6486   -1.228358\n",
              "6487   -1.228358\n",
              "6488   -1.228358\n",
              "6489   -1.228358\n",
              "6490   -1.228358\n",
              "6491   -1.228358\n",
              "6492   -1.228358\n",
              "Name: temp, Length: 6493, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xtDn0VbkRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#For debugging only\n",
        "#print(mean_temp, sd_temp, mean_atemp, sd_atemp, mean_humidity, sd_humidity, mean_windspeed, sd_windspeed)\n",
        "print(data_x[0:2])\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V30RCC7xdBjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For debugging only\n",
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}