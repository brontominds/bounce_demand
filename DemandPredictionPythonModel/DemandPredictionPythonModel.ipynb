{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemandPredictionPythonModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brontominds/bounce_demand/blob/v0.01/DemandPredictionPythonModel/DemandPredictionPythonModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-utKQafzbKAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f15c22b9-1ec9-4cc0-b8b3-1fed873870d5"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt  # For plotting graphs \n",
        "from datetime import datetime    # To access datetime \n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.optimizers import Adam,SGD,RMSprop,Adagrad\n",
        "\n",
        "\n",
        "\n",
        "#Add date time specific columns to the dataframe\n",
        "def datetime(df):\n",
        "  from datetime import datetime\n",
        "  df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "  df['year'] = df['datetime'].dt.year\n",
        "  df['month']=df['datetime'].dt.month\n",
        "  df['day'] = df['datetime'].dt.day \n",
        "  df['hour'] = df['datetime'].dt.hour\n",
        "  df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "  return df\n",
        "\n",
        "#Normalize a column of dataframe and return mean and sd\n",
        "def normalize(df,feature_name):\n",
        "  mean_value = df[feature_name].mean()\n",
        "  std_value = df[feature_name].std()\n",
        "  df[feature_name] = (df[feature_name] - mean_value) / std_value        \n",
        "  return (df, mean_value, std_value)\n",
        "\n",
        "\n",
        "#One hot encode data\n",
        "def dummy_data(data, columns):\n",
        "    for column in columns:\n",
        "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
        "        data = data.drop(column, axis=1)\n",
        "    return data\n",
        "\n",
        "#Drop Redundant Columns\n",
        "def drop_redundantcolumns(data):\n",
        "  return (data.drop([\"casual\",\"registered\"], axis=1))  \n",
        "\n",
        "#Create target variable and convert features dataframe to a numpy array\n",
        "def create_targetvariable(data, fraction=0.2):\n",
        "    data_y = data[\"count\"]\n",
        "    data_x = data.drop([\"count\"], axis=1)\n",
        "    return data_x.values, data_y\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0YEUZ1IUKSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PLotting functions\n",
        "%matplotlib inline\n",
        "def plotOutliers(df):\n",
        "  plt.figure(1)\n",
        "  plt.subplot(121)\n",
        "  sns.distplot(df); \n",
        "  plt.subplot(122)\n",
        "  df.plot.box(figsize=(16,5)) \n",
        "  plt.show()\n",
        "  \n",
        "def plotScatter(df1, dfTarget):\n",
        "  plt.scatter(df1,dfTarget,alpha=0.1,cmap='viridis')\n",
        "  \n",
        "def plotCorrelationHeatmap(df):\n",
        "  matrix = df.corr()\n",
        "  f, ax = plt.subplots(figsize=(30, 10))\n",
        "  sns.heatmap(matrix, vmax=.8, square=True, cmap=\"Greens\")\n",
        "  \n",
        "def plotCorrelationHeatMap1d(df):\n",
        "  corrMat = df.corr()\n",
        "  mask = np.array(corrMat)\n",
        "  mask[np.tril_indices_from(mask)] = False\n",
        "  fig, ax= plt.subplots(figsize=(60, 20))\n",
        "  sns.heatmap(corrMat, mask=mask,vmax=1., square=True,annot=True)\n",
        " \n",
        "  def plotCorrelationwithTarget(df):\n",
        "    corr_matrix = df.corr()\n",
        "    corr_target=corr_matrix[\"count\"].sort_values(ascending=False)\n",
        "    corr_target.plot.bar()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Zl-EG3cBUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read Training Data\n",
        "data=pd.read_csv(\"train.csv\")\n",
        "data_original=data\n",
        "\n",
        "#Add new features of date time\n",
        "data=datetime(data)\n",
        "data=data.drop('datetime',axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv_OBBjFVEE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot graphs if required\n",
        "#plotOutliers(data['atemp'])\n",
        "#plotScatter(data['humidity'], data['count'])\n",
        "#plotCorrelationHeatmap(data)\n",
        "#plotCorrelationHeatMap1d(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWRVTrqqU9uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform Data\n",
        "#Normalize weather data\n",
        "data, mean_temp, sd_temp=normalize(data,[\"temp\"])\n",
        "data,mean_atemp,sd_atemp=normalize(data,[\"atemp\"])\n",
        "data,mean_humidity,sd_humidity=normalize(data,[\"humidity\"])\n",
        "data,mean_windspeed,sd_windspeed=normalize(data,[\"windspeed\"])\n",
        "\n",
        "#One hot-encode categorical data\n",
        "data = dummy_data(data, [\"season\",\"weather\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n",
        "#TODO: Check which all features require hot encoding, and which work better without hot encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awuxCbq6dxMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shuffle data and split into training+validation, and testing\n",
        "#Training and Validation data kept together as Keras will do the auto split\n",
        "data=shuffle(data,random_state=1) #Seed=1 applied for ability to repeat same tests with parameters tuning\n",
        "\n",
        "testDataSplit=0.2 #0.3 means 30% data will be taken out for test and remaining for training+validation\n",
        "nrows = len(data)\n",
        "training_validation_rows = int(nrows*(1-testDataSplit))\n",
        "training_validation_data=data[0:training_validation_rows-1]\n",
        "test_data=data[training_validation_rows:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6fL547YeY9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop casual and registered users columns\n",
        "training_validation_data = drop_redundantcolumns(training_validation_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "data_x, data_y = create_targetvariable(training_validation_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKDHHP0wfagY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate NN Sequential Model\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = data_x.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='softplus'))\n",
        "\n",
        "#Define optimizer\n",
        "adam = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer=adam, metrics=['mean_absolute_error','mean_squared_error'])\n",
        "#NN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqrlKX-geLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define callbacks for model training\n",
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose =1, save_best_only = True, mode ='auto')\n",
        "early_stop=EarlyStopping(monitor='val_loss',patience=10)\n",
        "callbacks_list = [checkpoint,early_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfpV__-fal1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define plot function to show training and validation losses\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPQpyEsPg2Gu",
        "colab_type": "code",
        "outputId": "9903dc83-5457-4fa4-dcad-ed059c335d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#TRAIN MODEL\n",
        "history=NN_model.fit(data_x, data_y, epochs=1000, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8708 samples, validate on 2177 samples\n",
            "Epoch 1/1000\n",
            "8708/8708 [==============================] - 2s 214us/step - loss: 2.1842 - mean_absolute_error: 143.6277 - mean_squared_error: 41780.7941 - val_loss: 2.0549 - val_mean_absolute_error: 138.0659 - val_mean_squared_error: 37253.7161\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.05492, saving model to Weights-001--2.05492.hdf5\n",
            "Epoch 2/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 1.9091 - mean_absolute_error: 139.7101 - mean_squared_error: 40606.2521 - val_loss: 1.4221 - val_mean_absolute_error: 122.5117 - val_mean_squared_error: 33679.4904\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.05492 to 1.42214, saving model to Weights-002--1.42214.hdf5\n",
            "Epoch 3/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 1.1057 - mean_absolute_error: 111.1046 - mean_squared_error: 28079.4938 - val_loss: 0.9438 - val_mean_absolute_error: 105.9648 - val_mean_squared_error: 26933.0099\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.42214 to 0.94380, saving model to Weights-003--0.94380.hdf5\n",
            "Epoch 4/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 1.0192 - mean_absolute_error: 108.6709 - mean_squared_error: 27068.8096 - val_loss: 0.9207 - val_mean_absolute_error: 103.6632 - val_mean_squared_error: 24887.9562\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.94380 to 0.92069, saving model to Weights-004--0.92069.hdf5\n",
            "Epoch 5/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 1.0195 - mean_absolute_error: 109.0211 - mean_squared_error: 27364.7977 - val_loss: 1.1777 - val_mean_absolute_error: 106.5288 - val_mean_squared_error: 24166.5539\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.92069\n",
            "Epoch 6/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.9187 - mean_absolute_error: 105.2227 - mean_squared_error: 26147.3012 - val_loss: 0.7905 - val_mean_absolute_error: 94.9605 - val_mean_squared_error: 20690.8858\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.92069 to 0.79050, saving model to Weights-006--0.79050.hdf5\n",
            "Epoch 7/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.7633 - mean_absolute_error: 99.0634 - mean_squared_error: 23738.2430 - val_loss: 0.5741 - val_mean_absolute_error: 86.9606 - val_mean_squared_error: 16917.8197\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.79050 to 0.57415, saving model to Weights-007--0.57415.hdf5\n",
            "Epoch 8/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.5755 - mean_absolute_error: 90.9021 - mean_squared_error: 20660.6337 - val_loss: 0.5269 - val_mean_absolute_error: 82.9138 - val_mean_squared_error: 17287.1233\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57415 to 0.52695, saving model to Weights-008--0.52695.hdf5\n",
            "Epoch 9/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.4689 - mean_absolute_error: 85.1088 - mean_squared_error: 18400.0841 - val_loss: 0.7452 - val_mean_absolute_error: 88.6774 - val_mean_squared_error: 19524.9663\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.52695\n",
            "Epoch 10/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.4301 - mean_absolute_error: 82.7380 - mean_squared_error: 17587.2220 - val_loss: 0.3827 - val_mean_absolute_error: 78.8321 - val_mean_squared_error: 15893.5629\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.52695 to 0.38269, saving model to Weights-010--0.38269.hdf5\n",
            "Epoch 11/1000\n",
            "8708/8708 [==============================] - 1s 130us/step - loss: 0.4493 - mean_absolute_error: 86.1941 - mean_squared_error: 18940.2219 - val_loss: 0.3861 - val_mean_absolute_error: 78.5947 - val_mean_squared_error: 15798.1566\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.38269\n",
            "Epoch 12/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3879 - mean_absolute_error: 80.9688 - mean_squared_error: 16971.1547 - val_loss: 0.4620 - val_mean_absolute_error: 80.9492 - val_mean_squared_error: 14281.4611\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.38269\n",
            "Epoch 13/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.3697 - mean_absolute_error: 79.3628 - mean_squared_error: 16218.0557 - val_loss: 0.5437 - val_mean_absolute_error: 104.3604 - val_mean_squared_error: 20150.7058\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.38269\n",
            "Epoch 14/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.4153 - mean_absolute_error: 84.2429 - mean_squared_error: 18362.1842 - val_loss: 0.3242 - val_mean_absolute_error: 76.3519 - val_mean_squared_error: 14417.3557\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.38269 to 0.32424, saving model to Weights-014--0.32424.hdf5\n",
            "Epoch 15/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.3556 - mean_absolute_error: 78.3546 - mean_squared_error: 15957.3133 - val_loss: 0.4099 - val_mean_absolute_error: 79.5643 - val_mean_squared_error: 16897.1777\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.32424\n",
            "Epoch 16/1000\n",
            "8708/8708 [==============================] - 1s 133us/step - loss: 0.3592 - mean_absolute_error: 77.7360 - mean_squared_error: 15660.9378 - val_loss: 0.3005 - val_mean_absolute_error: 72.1001 - val_mean_squared_error: 13657.8697\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.32424 to 0.30052, saving model to Weights-016--0.30052.hdf5\n",
            "Epoch 17/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.3249 - mean_absolute_error: 75.0128 - mean_squared_error: 14772.7169 - val_loss: 0.3559 - val_mean_absolute_error: 72.3830 - val_mean_squared_error: 13021.3005\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.30052\n",
            "Epoch 18/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.3409 - mean_absolute_error: 75.4050 - mean_squared_error: 14671.9870 - val_loss: 0.3078 - val_mean_absolute_error: 72.4348 - val_mean_squared_error: 14279.5549\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.30052\n",
            "Epoch 19/1000\n",
            "8708/8708 [==============================] - 1s 122us/step - loss: 0.3227 - mean_absolute_error: 73.6196 - mean_squared_error: 14132.8877 - val_loss: 0.3093 - val_mean_absolute_error: 69.3279 - val_mean_squared_error: 12558.3929\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.30052\n",
            "Epoch 20/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3056 - mean_absolute_error: 71.8590 - mean_squared_error: 13436.5668 - val_loss: 0.2974 - val_mean_absolute_error: 66.9669 - val_mean_squared_error: 12318.3263\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.30052 to 0.29738, saving model to Weights-020--0.29738.hdf5\n",
            "Epoch 21/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.3201 - mean_absolute_error: 71.9497 - mean_squared_error: 13465.3213 - val_loss: 0.3058 - val_mean_absolute_error: 70.7824 - val_mean_squared_error: 13393.3537\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.29738\n",
            "Epoch 22/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2825 - mean_absolute_error: 67.7581 - mean_squared_error: 11971.9648 - val_loss: 0.2786 - val_mean_absolute_error: 65.9226 - val_mean_squared_error: 10285.3899\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.29738 to 0.27856, saving model to Weights-022--0.27856.hdf5\n",
            "Epoch 23/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.3312 - mean_absolute_error: 70.7821 - mean_squared_error: 13011.4989 - val_loss: 0.4127 - val_mean_absolute_error: 76.3887 - val_mean_squared_error: 13872.8707\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.27856\n",
            "Epoch 24/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2727 - mean_absolute_error: 66.1412 - mean_squared_error: 11236.5169 - val_loss: 0.3997 - val_mean_absolute_error: 68.9648 - val_mean_squared_error: 11676.0729\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.27856\n",
            "Epoch 25/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2798 - mean_absolute_error: 65.9492 - mean_squared_error: 11173.8672 - val_loss: 0.2354 - val_mean_absolute_error: 60.3395 - val_mean_squared_error: 10114.4095\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.27856 to 0.23537, saving model to Weights-025--0.23537.hdf5\n",
            "Epoch 26/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2506 - mean_absolute_error: 62.9837 - mean_squared_error: 10216.9984 - val_loss: 0.3360 - val_mean_absolute_error: 65.6248 - val_mean_squared_error: 10609.9380\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.23537\n",
            "Epoch 27/1000\n",
            "8708/8708 [==============================] - 1s 137us/step - loss: 0.2974 - mean_absolute_error: 66.5413 - mean_squared_error: 11433.7273 - val_loss: 0.2327 - val_mean_absolute_error: 59.4020 - val_mean_squared_error: 8998.9497\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.23537 to 0.23275, saving model to Weights-027--0.23275.hdf5\n",
            "Epoch 28/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2299 - mean_absolute_error: 59.9400 - mean_squared_error: 9156.6935 - val_loss: 0.2553 - val_mean_absolute_error: 57.5921 - val_mean_squared_error: 8125.3358\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.23275\n",
            "Epoch 29/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2408 - mean_absolute_error: 60.3312 - mean_squared_error: 9212.0522 - val_loss: 0.2388 - val_mean_absolute_error: 58.6634 - val_mean_squared_error: 8531.8358\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.23275\n",
            "Epoch 30/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2390 - mean_absolute_error: 59.6463 - mean_squared_error: 8943.6158 - val_loss: 0.2280 - val_mean_absolute_error: 58.0987 - val_mean_squared_error: 8583.1227\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.23275 to 0.22803, saving model to Weights-030--0.22803.hdf5\n",
            "Epoch 31/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2415 - mean_absolute_error: 61.1065 - mean_squared_error: 9416.1221 - val_loss: 0.3230 - val_mean_absolute_error: 62.4934 - val_mean_squared_error: 9077.5572\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.22803\n",
            "Epoch 32/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 0.2332 - mean_absolute_error: 59.5337 - mean_squared_error: 8850.0561 - val_loss: 0.2114 - val_mean_absolute_error: 54.4194 - val_mean_squared_error: 7502.2957\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.22803 to 0.21138, saving model to Weights-032--0.21138.hdf5\n",
            "Epoch 33/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2409 - mean_absolute_error: 60.6202 - mean_squared_error: 9109.9508 - val_loss: 0.3099 - val_mean_absolute_error: 62.6497 - val_mean_squared_error: 9953.7802\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.21138\n",
            "Epoch 34/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2383 - mean_absolute_error: 59.9274 - mean_squared_error: 8896.6274 - val_loss: 0.2315 - val_mean_absolute_error: 60.5266 - val_mean_squared_error: 9943.8817\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.21138\n",
            "Epoch 35/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.2262 - mean_absolute_error: 58.5496 - mean_squared_error: 8533.4238 - val_loss: 0.2359 - val_mean_absolute_error: 57.3609 - val_mean_squared_error: 8402.4298\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.21138\n",
            "Epoch 36/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2279 - mean_absolute_error: 58.8812 - mean_squared_error: 8639.2567 - val_loss: 0.2610 - val_mean_absolute_error: 61.2417 - val_mean_squared_error: 9330.5366\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.21138\n",
            "Epoch 37/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2395 - mean_absolute_error: 59.4465 - mean_squared_error: 8729.3288 - val_loss: 0.2956 - val_mean_absolute_error: 56.8045 - val_mean_squared_error: 7023.7385\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.21138\n",
            "Epoch 38/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2378 - mean_absolute_error: 59.0853 - mean_squared_error: 8575.7801 - val_loss: 0.2225 - val_mean_absolute_error: 54.7073 - val_mean_squared_error: 7455.8425\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.21138\n",
            "Epoch 39/1000\n",
            "8708/8708 [==============================] - 1s 127us/step - loss: 0.2092 - mean_absolute_error: 56.2582 - mean_squared_error: 7812.1188 - val_loss: 0.2187 - val_mean_absolute_error: 52.0015 - val_mean_squared_error: 6267.4166\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.21138\n",
            "Epoch 40/1000\n",
            "8708/8708 [==============================] - 1s 123us/step - loss: 0.2247 - mean_absolute_error: 57.9082 - mean_squared_error: 8370.2837 - val_loss: 0.2578 - val_mean_absolute_error: 58.1293 - val_mean_squared_error: 8658.3333\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.21138\n",
            "Epoch 41/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2102 - mean_absolute_error: 56.6967 - mean_squared_error: 7947.1307 - val_loss: 0.2036 - val_mean_absolute_error: 51.8818 - val_mean_squared_error: 6308.6434\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.21138 to 0.20365, saving model to Weights-041--0.20365.hdf5\n",
            "Epoch 42/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2172 - mean_absolute_error: 57.4528 - mean_squared_error: 8050.2778 - val_loss: 0.2400 - val_mean_absolute_error: 57.5194 - val_mean_squared_error: 8134.0625\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.20365\n",
            "Epoch 43/1000\n",
            "8708/8708 [==============================] - 1s 130us/step - loss: 0.2138 - mean_absolute_error: 56.1136 - mean_squared_error: 7692.6305 - val_loss: 0.2200 - val_mean_absolute_error: 54.2354 - val_mean_squared_error: 6653.2693\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.20365\n",
            "Epoch 44/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2185 - mean_absolute_error: 57.4614 - mean_squared_error: 8022.6429 - val_loss: 0.2041 - val_mean_absolute_error: 53.3689 - val_mean_squared_error: 7371.4663\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.20365\n",
            "Epoch 45/1000\n",
            "8708/8708 [==============================] - 1s 133us/step - loss: 0.2178 - mean_absolute_error: 57.0232 - mean_squared_error: 8001.4593 - val_loss: 0.2230 - val_mean_absolute_error: 56.9553 - val_mean_squared_error: 8426.2739\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.20365\n",
            "Epoch 46/1000\n",
            "8708/8708 [==============================] - 1s 132us/step - loss: 0.2547 - mean_absolute_error: 59.7403 - mean_squared_error: 8805.1366 - val_loss: 0.2048 - val_mean_absolute_error: 53.3405 - val_mean_squared_error: 7056.4849\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.20365\n",
            "Epoch 47/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.2057 - mean_absolute_error: 55.5605 - mean_squared_error: 7533.5450 - val_loss: 0.2016 - val_mean_absolute_error: 51.7192 - val_mean_squared_error: 6012.5996\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.20365 to 0.20156, saving model to Weights-047--0.20156.hdf5\n",
            "Epoch 48/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2093 - mean_absolute_error: 55.8160 - mean_squared_error: 7505.1147 - val_loss: 0.2124 - val_mean_absolute_error: 51.4350 - val_mean_squared_error: 6046.0932\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.20156\n",
            "Epoch 49/1000\n",
            "8708/8708 [==============================] - 1s 124us/step - loss: 0.1994 - mean_absolute_error: 54.9800 - mean_squared_error: 7353.6716 - val_loss: 0.2086 - val_mean_absolute_error: 52.1111 - val_mean_squared_error: 6386.9745\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.20156\n",
            "Epoch 50/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2121 - mean_absolute_error: 56.2182 - mean_squared_error: 7765.1363 - val_loss: 0.2566 - val_mean_absolute_error: 54.5926 - val_mean_squared_error: 6890.7903\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.20156\n",
            "Epoch 51/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2117 - mean_absolute_error: 55.8756 - mean_squared_error: 7606.9326 - val_loss: 0.2272 - val_mean_absolute_error: 57.9149 - val_mean_squared_error: 7617.3545\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.20156\n",
            "Epoch 52/1000\n",
            "8708/8708 [==============================] - 1s 129us/step - loss: 0.2278 - mean_absolute_error: 57.4728 - mean_squared_error: 8092.2990 - val_loss: 0.4625 - val_mean_absolute_error: 68.8491 - val_mean_squared_error: 11559.5232\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.20156\n",
            "Epoch 53/1000\n",
            "8708/8708 [==============================] - 1s 131us/step - loss: 0.2172 - mean_absolute_error: 56.0883 - mean_squared_error: 7571.0692 - val_loss: 0.2168 - val_mean_absolute_error: 53.7451 - val_mean_squared_error: 7112.8999\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.20156\n",
            "Epoch 54/1000\n",
            "8708/8708 [==============================] - 1s 128us/step - loss: 0.2099 - mean_absolute_error: 55.4914 - mean_squared_error: 7495.0230 - val_loss: 0.2225 - val_mean_absolute_error: 55.8354 - val_mean_squared_error: 7388.3490\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.20156\n",
            "Epoch 55/1000\n",
            "8708/8708 [==============================] - 1s 140us/step - loss: 0.1997 - mean_absolute_error: 54.8925 - mean_squared_error: 7371.4325 - val_loss: 0.2953 - val_mean_absolute_error: 70.0221 - val_mean_squared_error: 10380.7499\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.20156\n",
            "Epoch 56/1000\n",
            "8708/8708 [==============================] - 1s 126us/step - loss: 0.2094 - mean_absolute_error: 55.6973 - mean_squared_error: 7503.5271 - val_loss: 0.2196 - val_mean_absolute_error: 54.8472 - val_mean_squared_error: 7027.5134\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.20156\n",
            "Epoch 57/1000\n",
            "8708/8708 [==============================] - 1s 125us/step - loss: 0.2234 - mean_absolute_error: 56.6278 - mean_squared_error: 7887.1674 - val_loss: 0.2556 - val_mean_absolute_error: 59.1789 - val_mean_squared_error: 8274.2631\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.20156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yld7jrdxg2J5",
        "colab_type": "code",
        "outputId": "054b1a1f-b5af-43f6-932b-ce03460bb651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Save the trained model to a pickle file\n",
        "import pickle\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(NN_model,'BounceDemandPredictionv001.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BounceDemandPredictionv001.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lN0leLJEKk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "lst=[mean_temp[0],mean_humidity[0],mean_windspeed[0],mean_atemp[0],sd_temp[0],sd_humidity[0],sd_windspeed[0],sd_atemp[0]]\n",
        " \n",
        "df = pd.DataFrame([lst],columns =['mean_temp', 'mean_humidity','mean_windspeed','mean_atemp','sd_temp','sd_humidity','sd_windspeed','sd_atemp']) \n",
        "df.to_csv('data_mean_std.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxqXbImhxIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define transformation functions\n",
        "def transform_temp(temp):\n",
        "  return ((temp-mean_temp[0])/sd_temp[0])\n",
        "\n",
        "def transform_atemp(atemp):\n",
        "  return ((atemp-mean_atemp[0])/sd_atemp[0])\n",
        "\n",
        "def transform_humidity(humidity):\n",
        "  return ((humidity-mean_humidity[0])/sd_humidity[0])\n",
        "\n",
        "def transform_windspeed(windspeed):\n",
        "   return ((windspeed-mean_windspeed[0])/sd_windspeed[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMswIHRZirY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate on test data\n",
        "\n",
        "#Drop casual and registered users columns\n",
        "test_data = drop_redundantcolumns(test_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "test_data_x, test_data_y = create_targetvariable(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaG78syOirhK",
        "colab_type": "code",
        "outputId": "80c24db0-0022-4d54-954f-757fe4c17ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scores=NN_model.evaluate(test_data_x,test_data_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2178/2178 [==============================] - 0s 37us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAmOOv7nkJ17",
        "colab_type": "code",
        "outputId": "88821592-e626-4d3c-895e-df5d4ab2c2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test1_loss=scores[0]\n",
        "test1_mae=scores[1]\n",
        "test1_mse=scores[2]\n",
        "\n",
        "test1_mae\n",
        "\n",
        "#Evaluate on Test Data Complete"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.0256134985345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqHHPciAkJ5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L--WIAJFkdhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle submission\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "test_original=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p17NxDxBkp_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform Test Data\n",
        "#Add new features of date time\n",
        "test=datetime(test)\n",
        "test=test.drop('datetime',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MoeVzXUmdrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Normalize weather data\n",
        "test[\"temp\"] = transform_temp(test[\"temp\"])\n",
        "test[\"atemp\"] = transform_atemp(test[\"atemp\"])\n",
        "test[\"humidity\"] = transform_humidity(test[\"humidity\"])\n",
        "test[\"windspeed\"] = transform_windspeed(test[\"windspeed\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U7ceaIQolZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#test, mean_temp, sd_temp=normalize(test,[\"temp\"])\n",
        "#test,mean_atemp,sd_atemp=normalize(test,[\"atemp\"])\n",
        "#test,mean_humidity,sd_humidity=normalize(test,[\"humidity\"])\n",
        "#test,mean_windspeed,sd_windspeed=normalize(test,[\"windspeed\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5IW52FNmmIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#One hot-encode categorical data\n",
        "test = dummy_data(test, [\"season\",\"weather\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHI_qAPmO6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction=NN_model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vcmvD2rnLy8",
        "colab_type": "code",
        "outputId": "3246dd38-45ae-424e-df8b-6f5e6fb1ab59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "evaluation=test_original['datetime'].to_frame()\n",
        "evaluation[\"count\"]=prediction\n",
        "evaluation[\"count\"] = evaluation[\"count\"].astype(int)\n",
        "evaluation[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011-01-20 05:00:00</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-01-20 06:00:00</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-01-20 07:00:00</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-01-20 08:00:00</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2011-01-20 09:00:00</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  count\n",
              "0  2011-01-20 00:00:00      6\n",
              "1  2011-01-20 01:00:00      5\n",
              "2  2011-01-20 02:00:00      2\n",
              "3  2011-01-20 03:00:00      1\n",
              "4  2011-01-20 04:00:00      1\n",
              "5  2011-01-20 05:00:00      7\n",
              "6  2011-01-20 06:00:00     50\n",
              "7  2011-01-20 07:00:00    140\n",
              "8  2011-01-20 08:00:00    178\n",
              "9  2011-01-20 09:00:00     58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpa7EWLNngP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation.to_csv(\"submission_anupam.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FZp--YblL2f",
        "colab_type": "code",
        "outputId": "ef88bb3b-2ec2-4a52-cbea-98eff844d0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -1.228358\n",
              "1      -1.228358\n",
              "2      -1.228358\n",
              "3      -1.228358\n",
              "4      -1.228358\n",
              "5      -1.333599\n",
              "6      -1.438841\n",
              "7      -1.438841\n",
              "8      -1.438841\n",
              "9      -1.333599\n",
              "10     -1.228358\n",
              "11     -1.123116\n",
              "12     -1.017874\n",
              "13     -1.123116\n",
              "14     -1.017874\n",
              "15     -0.912633\n",
              "16     -1.017874\n",
              "17     -1.017874\n",
              "18     -1.228358\n",
              "19     -1.228358\n",
              "20     -1.228358\n",
              "21     -1.333599\n",
              "22     -1.333599\n",
              "23     -1.333599\n",
              "24     -1.333599\n",
              "25     -1.333599\n",
              "26     -1.333599\n",
              "27     -1.438841\n",
              "28     -1.438841\n",
              "29     -1.333599\n",
              "          ...   \n",
              "6463   -1.333599\n",
              "6464   -0.807391\n",
              "6465   -1.438841\n",
              "6466   -1.544083\n",
              "6467   -1.544083\n",
              "6468   -1.544083\n",
              "6469   -1.649324\n",
              "6470   -1.649324\n",
              "6471   -1.754566\n",
              "6472   -1.754566\n",
              "6473   -1.859808\n",
              "6474   -1.754566\n",
              "6475   -1.754566\n",
              "6476   -1.754566\n",
              "6477   -1.859808\n",
              "6478   -1.649324\n",
              "6479   -1.544083\n",
              "6480   -1.438841\n",
              "6481   -1.333599\n",
              "6482   -1.228358\n",
              "6483   -1.123116\n",
              "6484   -1.123116\n",
              "6485   -1.228358\n",
              "6486   -1.228358\n",
              "6487   -1.228358\n",
              "6488   -1.228358\n",
              "6489   -1.228358\n",
              "6490   -1.228358\n",
              "6491   -1.228358\n",
              "6492   -1.228358\n",
              "Name: temp, Length: 6493, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xtDn0VbkRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#For debugging only\n",
        "#print(mean_temp, sd_temp, mean_atemp, sd_atemp, mean_humidity, sd_humidity, mean_windspeed, sd_windspeed)\n",
        "print(data_x[0:2])\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V30RCC7xdBjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For debugging only\n",
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}