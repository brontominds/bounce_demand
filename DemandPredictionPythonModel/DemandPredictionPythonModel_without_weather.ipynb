{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemandPredictionPythonModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brontominds/bounce_demand/blob/v0.01/DemandPredictionPythonModel/DemandPredictionPythonModel_without_weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-utKQafzbKAm",
        "outputId": "4c317f41-0d31-41cd-a27d-d0930457907c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt  # For plotting graphs \n",
        "from datetime import datetime    # To access datetime \n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.optimizers import Adam,SGD,RMSprop,Adagrad\n",
        "\n",
        "\n",
        "\n",
        "#Add date time specific columns to the dataframe\n",
        "def datetime(df):\n",
        "  from datetime import datetime\n",
        "  df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "  df['year'] = df['datetime'].dt.year\n",
        "  df['month']=df['datetime'].dt.month\n",
        "  df['day'] = df['datetime'].dt.day \n",
        "  df['hour'] = df['datetime'].dt.hour\n",
        "  df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "  return df\n",
        "\n",
        "#Normalize a column of dataframe and return mean and sd\n",
        "'''def normalize(df,feature_name):\n",
        "  mean_value = df[feature_name].mean()\n",
        "  std_value = df[feature_name].std()\n",
        "  df[feature_name] = (df[feature_name] - mean_value) / std_value        \n",
        "  return (df, mean_value, std_value)'''\n",
        "\n",
        "\n",
        "#One hot encode data\n",
        "def dummy_data(data, columns):\n",
        "    for column in columns:\n",
        "        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
        "        data = data.drop(column, axis=1)\n",
        "    return data\n",
        "\n",
        "#Drop Redundant Columns\n",
        "def drop_redundantcolumns(data):\n",
        "  return (data.drop([\"casual\",\"registered\"], axis=1))  \n",
        "\n",
        "#Create target variable and convert features dataframe to a numpy array\n",
        "def create_targetvariable(data, fraction=0.2):\n",
        "    data_y = data[\"count\"]\n",
        "    data_x = data.drop([\"count\"], axis=1)\n",
        "    return data_x.values, data_y\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j0YEUZ1IUKSe",
        "colab": {}
      },
      "source": [
        "#PLotting functions\n",
        "%matplotlib inline\n",
        "def plotOutliers(df):\n",
        "  plt.figure(1)\n",
        "  plt.subplot(121)\n",
        "  sns.distplot(df); \n",
        "  plt.subplot(122)\n",
        "  df.plot.box(figsize=(16,5)) \n",
        "  plt.show()\n",
        "  \n",
        "def plotScatter(df1, dfTarget):\n",
        "  plt.scatter(df1,dfTarget,alpha=0.1,cmap='viridis')\n",
        "  \n",
        "def plotCorrelationHeatmap(df):\n",
        "  matrix = df.corr()\n",
        "  f, ax = plt.subplots(figsize=(30, 10))\n",
        "  sns.heatmap(matrix, vmax=.8, square=True, cmap=\"Greens\")\n",
        "  \n",
        "def plotCorrelationHeatMap1d(df):\n",
        "  corrMat = df.corr()\n",
        "  mask = np.array(corrMat)\n",
        "  mask[np.tril_indices_from(mask)] = False\n",
        "  fig, ax= plt.subplots(figsize=(60, 20))\n",
        "  sns.heatmap(corrMat, mask=mask,vmax=1., square=True,annot=True)\n",
        " \n",
        "  def plotCorrelationwithTarget(df):\n",
        "    corr_matrix = df.corr()\n",
        "    corr_target=corr_matrix[\"count\"].sort_values(ascending=False)\n",
        "    corr_target.plot.bar()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5Zl-EG3cBUI",
        "colab": {}
      },
      "source": [
        "#Read Training Data\n",
        "data=pd.read_csv(\"train.csv\")\n",
        "data_original=data\n",
        "\n",
        "#Add new features of date time\n",
        "data=datetime(data)\n",
        "data=data.drop(['datetime','atemp','temp','weather','humidity','windspeed'],axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hv_OBBjFVEE8",
        "colab": {}
      },
      "source": [
        "#Plot graphs if required\n",
        "#plotOutliers(data['atemp'])\n",
        "#plotScatter(data['humidity'], data['count'])\n",
        "#plotCorrelationHeatmap(data)\n",
        "#plotCorrelationHeatMap1d(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IWRVTrqqU9uG",
        "colab": {}
      },
      "source": [
        "#Transform Data\n",
        "#Normalize weather data\n",
        "#data, mean_temp, sd_temp=normalize(data,[\"temp\"])\n",
        "#data,mean_atemp,sd_atemp=normalize(data,[\"atemp\"])\n",
        "#data,mean_humidity,sd_humidity=normalize(data,[\"humidity\"])\n",
        "#data,mean_windspeed,sd_windspeed=normalize(data,[\"windspeed\"])\n",
        "\n",
        "#One hot-encode categorical data\n",
        "data = dummy_data(data, [\"season\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n",
        "#TODO: Check which all features require hot encoding, and which work better without hot encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "awuxCbq6dxMg",
        "colab": {}
      },
      "source": [
        "#Shuffle data and split into training+validation, and testing\n",
        "#Training and Validation data kept together as Keras will do the auto split\n",
        "data=shuffle(data,random_state=1) #Seed=1 applied for ability to repeat same tests with parameters tuning\n",
        "\n",
        "testDataSplit=0.2 #0.3 means 30% data will be taken out for test and remaining for training+validation\n",
        "nrows = len(data)\n",
        "training_validation_rows = int(nrows*(1-testDataSplit))\n",
        "training_validation_data=data[0:training_validation_rows-1]\n",
        "test_data=data[training_validation_rows:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q6fL547YeY9W",
        "colab": {}
      },
      "source": [
        "#Drop casual and registered users columns\n",
        "training_validation_data = drop_redundantcolumns(training_validation_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "data_x, data_y = create_targetvariable(training_validation_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cKDHHP0wfagY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "8bfcfb15-1bc8-4057-ec32-7b044fa81bb3"
      },
      "source": [
        "#Generate NN Sequential Model\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = data_x.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='softplus'))\n",
        "\n",
        "#Define optimizer\n",
        "adam = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_logarithmic_error', optimizer=adam, metrics=['mean_absolute_error','mean_squared_error'])\n",
        "#NN_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 10:25:38.935149 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0719 10:25:38.978754 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0719 10:25:38.987677 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0719 10:25:39.070726 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0719 10:25:39.079501 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VFqrlKX-geLl",
        "colab": {}
      },
      "source": [
        "#Define callbacks for model training\n",
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose =1, save_best_only = True, mode ='auto')\n",
        "early_stop=EarlyStopping(monitor='val_loss',patience=10)\n",
        "callbacks_list = [checkpoint,early_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pKfpV__-fal1",
        "colab": {}
      },
      "source": [
        "#Define plot function to show training and validation losses\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UPQpyEsPg2Gu",
        "outputId": "0a8ae628-abdf-4a24-9100-f58405b0f8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#TRAIN MODEL\n",
        "history=NN_model.fit(data_x, data_y, epochs=1000, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 10:25:51.970978 140065016743808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0719 10:25:52.009927 140065016743808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6965 samples, validate on 1742 samples\n",
            "Epoch 1/1000\n",
            "6965/6965 [==============================] - 2s 230us/step - loss: 2.1533 - mean_absolute_error: 144.5902 - mean_squared_error: 41793.5868 - val_loss: 1.9498 - val_mean_absolute_error: 142.3216 - val_mean_squared_error: 42797.4803\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.94977, saving model to Weights-001--1.94977.hdf5\n",
            "Epoch 2/1000\n",
            "6965/6965 [==============================] - 1s 113us/step - loss: 2.0339 - mean_absolute_error: 144.1125 - mean_squared_error: 42005.7671 - val_loss: 1.9403 - val_mean_absolute_error: 138.2501 - val_mean_squared_error: 39388.3767\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.94977 to 1.94032, saving model to Weights-002--1.94032.hdf5\n",
            "Epoch 3/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 2.0334 - mean_absolute_error: 143.8975 - mean_squared_error: 41934.2328 - val_loss: 1.9340 - val_mean_absolute_error: 137.7118 - val_mean_squared_error: 39066.6814\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.94032 to 1.93397, saving model to Weights-003--1.93397.hdf5\n",
            "Epoch 4/1000\n",
            "6965/6965 [==============================] - 1s 114us/step - loss: 2.0325 - mean_absolute_error: 143.6575 - mean_squared_error: 41634.7153 - val_loss: 1.9082 - val_mean_absolute_error: 139.6600 - val_mean_squared_error: 41131.7035\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.93397 to 1.90819, saving model to Weights-004--1.90819.hdf5\n",
            "Epoch 5/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 1.9920 - mean_absolute_error: 142.9492 - mean_squared_error: 41623.6428 - val_loss: 1.8266 - val_mean_absolute_error: 139.3455 - val_mean_squared_error: 42038.5859\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.90819 to 1.82664, saving model to Weights-005--1.82664.hdf5\n",
            "Epoch 6/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 1.6140 - mean_absolute_error: 129.4001 - mean_squared_error: 36098.2735 - val_loss: 0.9752 - val_mean_absolute_error: 106.7282 - val_mean_squared_error: 29792.6598\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.82664 to 0.97525, saving model to Weights-006--0.97525.hdf5\n",
            "Epoch 7/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 1.1503 - mean_absolute_error: 109.3506 - mean_squared_error: 26829.6346 - val_loss: 1.5077 - val_mean_absolute_error: 113.3541 - val_mean_squared_error: 20104.1324\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.97525\n",
            "Epoch 8/1000\n",
            "6965/6965 [==============================] - 1s 113us/step - loss: 0.6653 - mean_absolute_error: 89.7731 - mean_squared_error: 19584.3407 - val_loss: 0.5448 - val_mean_absolute_error: 83.5935 - val_mean_squared_error: 17280.7825\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.97525 to 0.54478, saving model to Weights-008--0.54478.hdf5\n",
            "Epoch 9/1000\n",
            "6965/6965 [==============================] - 1s 116us/step - loss: 0.5726 - mean_absolute_error: 85.8849 - mean_squared_error: 18077.5436 - val_loss: 0.5300 - val_mean_absolute_error: 82.9699 - val_mean_squared_error: 16273.8021\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.54478 to 0.52998, saving model to Weights-009--0.52998.hdf5\n",
            "Epoch 10/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 0.5916 - mean_absolute_error: 87.8777 - mean_squared_error: 18782.1581 - val_loss: 0.4741 - val_mean_absolute_error: 81.4007 - val_mean_squared_error: 17207.2668\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.52998 to 0.47406, saving model to Weights-010--0.47406.hdf5\n",
            "Epoch 11/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 0.5237 - mean_absolute_error: 84.3607 - mean_squared_error: 17369.9274 - val_loss: 0.6492 - val_mean_absolute_error: 90.1792 - val_mean_squared_error: 15974.3246\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.47406\n",
            "Epoch 12/1000\n",
            "6965/6965 [==============================] - 1s 110us/step - loss: 0.5361 - mean_absolute_error: 84.9443 - mean_squared_error: 17384.3191 - val_loss: 0.5054 - val_mean_absolute_error: 85.1809 - val_mean_squared_error: 19309.9670\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.47406\n",
            "Epoch 13/1000\n",
            "6965/6965 [==============================] - 1s 113us/step - loss: 0.5165 - mean_absolute_error: 83.1569 - mean_squared_error: 16719.8335 - val_loss: 0.4445 - val_mean_absolute_error: 80.3698 - val_mean_squared_error: 16726.1456\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.47406 to 0.44454, saving model to Weights-013--0.44454.hdf5\n",
            "Epoch 14/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.5152 - mean_absolute_error: 83.4321 - mean_squared_error: 16593.5335 - val_loss: 0.4853 - val_mean_absolute_error: 83.7698 - val_mean_squared_error: 18599.3552\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.44454\n",
            "Epoch 15/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4912 - mean_absolute_error: 81.4325 - mean_squared_error: 16038.4326 - val_loss: 0.4393 - val_mean_absolute_error: 80.5635 - val_mean_squared_error: 16819.4376\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.44454 to 0.43931, saving model to Weights-015--0.43931.hdf5\n",
            "Epoch 16/1000\n",
            "6965/6965 [==============================] - 1s 111us/step - loss: 0.4864 - mean_absolute_error: 81.3369 - mean_squared_error: 15813.1025 - val_loss: 0.4919 - val_mean_absolute_error: 80.5437 - val_mean_squared_error: 16589.6220\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.43931\n",
            "Epoch 17/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.5149 - mean_absolute_error: 82.8985 - mean_squared_error: 16273.1173 - val_loss: 0.4611 - val_mean_absolute_error: 82.8344 - val_mean_squared_error: 17852.6283\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.43931\n",
            "Epoch 18/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4838 - mean_absolute_error: 80.9447 - mean_squared_error: 15841.8024 - val_loss: 0.4493 - val_mean_absolute_error: 77.6056 - val_mean_squared_error: 14008.8380\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.43931\n",
            "Epoch 19/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4870 - mean_absolute_error: 81.2829 - mean_squared_error: 15719.6618 - val_loss: 0.4462 - val_mean_absolute_error: 79.0723 - val_mean_squared_error: 15628.4414\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.43931\n",
            "Epoch 20/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.5104 - mean_absolute_error: 82.7135 - mean_squared_error: 16061.7412 - val_loss: 0.4314 - val_mean_absolute_error: 77.3237 - val_mean_squared_error: 14499.7911\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.43931 to 0.43137, saving model to Weights-020--0.43137.hdf5\n",
            "Epoch 21/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4909 - mean_absolute_error: 81.5575 - mean_squared_error: 15914.2418 - val_loss: 0.4230 - val_mean_absolute_error: 78.9747 - val_mean_squared_error: 15782.7754\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.43137 to 0.42298, saving model to Weights-021--0.42298.hdf5\n",
            "Epoch 22/1000\n",
            "6965/6965 [==============================] - 1s 111us/step - loss: 0.4782 - mean_absolute_error: 80.3031 - mean_squared_error: 15466.6063 - val_loss: 0.4304 - val_mean_absolute_error: 76.5906 - val_mean_squared_error: 13985.4314\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.42298\n",
            "Epoch 23/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4805 - mean_absolute_error: 80.4953 - mean_squared_error: 15430.8156 - val_loss: 0.4293 - val_mean_absolute_error: 76.8354 - val_mean_squared_error: 14285.9047\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.42298\n",
            "Epoch 24/1000\n",
            "6965/6965 [==============================] - 1s 112us/step - loss: 0.4647 - mean_absolute_error: 79.5282 - mean_squared_error: 14938.2155 - val_loss: 0.4971 - val_mean_absolute_error: 78.5184 - val_mean_squared_error: 13457.7717\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.42298\n",
            "Epoch 25/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4999 - mean_absolute_error: 82.2721 - mean_squared_error: 15987.9644 - val_loss: 0.4227 - val_mean_absolute_error: 76.8557 - val_mean_squared_error: 14039.0610\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.42298 to 0.42269, saving model to Weights-025--0.42269.hdf5\n",
            "Epoch 26/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4678 - mean_absolute_error: 79.7107 - mean_squared_error: 14967.5220 - val_loss: 0.4153 - val_mean_absolute_error: 77.6392 - val_mean_squared_error: 14895.2349\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.42269 to 0.41535, saving model to Weights-026--0.41535.hdf5\n",
            "Epoch 27/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4806 - mean_absolute_error: 80.5170 - mean_squared_error: 15441.9574 - val_loss: 0.4205 - val_mean_absolute_error: 78.2741 - val_mean_squared_error: 15260.9845\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.41535\n",
            "Epoch 28/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4836 - mean_absolute_error: 81.1842 - mean_squared_error: 15421.0201 - val_loss: 0.4134 - val_mean_absolute_error: 76.2848 - val_mean_squared_error: 13835.0496\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.41535 to 0.41339, saving model to Weights-028--0.41339.hdf5\n",
            "Epoch 29/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4810 - mean_absolute_error: 80.7113 - mean_squared_error: 15437.3674 - val_loss: 0.4552 - val_mean_absolute_error: 77.9583 - val_mean_squared_error: 14485.2303\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.41339\n",
            "Epoch 30/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4628 - mean_absolute_error: 79.4531 - mean_squared_error: 14955.1631 - val_loss: 0.4106 - val_mean_absolute_error: 77.1166 - val_mean_squared_error: 14673.9928\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.41339 to 0.41058, saving model to Weights-030--0.41058.hdf5\n",
            "Epoch 31/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4499 - mean_absolute_error: 79.1799 - mean_squared_error: 14793.6028 - val_loss: 0.4224 - val_mean_absolute_error: 81.4014 - val_mean_squared_error: 17202.4327\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.41058\n",
            "Epoch 32/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4855 - mean_absolute_error: 81.4733 - mean_squared_error: 15647.5620 - val_loss: 0.4152 - val_mean_absolute_error: 76.9337 - val_mean_squared_error: 14481.5308\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.41058\n",
            "Epoch 33/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4714 - mean_absolute_error: 80.7675 - mean_squared_error: 15431.1360 - val_loss: 0.5921 - val_mean_absolute_error: 86.4475 - val_mean_squared_error: 18895.8666\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.41058\n",
            "Epoch 34/1000\n",
            "6965/6965 [==============================] - 1s 105us/step - loss: 0.4617 - mean_absolute_error: 79.3775 - mean_squared_error: 14982.8293 - val_loss: 0.5011 - val_mean_absolute_error: 84.3748 - val_mean_squared_error: 14153.7336\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.41058\n",
            "Epoch 35/1000\n",
            "6965/6965 [==============================] - 1s 105us/step - loss: 0.4737 - mean_absolute_error: 80.5706 - mean_squared_error: 15351.6785 - val_loss: 0.4134 - val_mean_absolute_error: 80.2277 - val_mean_squared_error: 16644.3154\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.41058\n",
            "Epoch 36/1000\n",
            "6965/6965 [==============================] - 1s 110us/step - loss: 0.4536 - mean_absolute_error: 78.8188 - mean_squared_error: 14745.0214 - val_loss: 0.4125 - val_mean_absolute_error: 76.4670 - val_mean_squared_error: 14225.2637\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.41058\n",
            "Epoch 37/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4564 - mean_absolute_error: 79.3172 - mean_squared_error: 14884.1587 - val_loss: 0.4663 - val_mean_absolute_error: 85.6586 - val_mean_squared_error: 19068.0024\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.41058\n",
            "Epoch 38/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4471 - mean_absolute_error: 78.9356 - mean_squared_error: 14692.6483 - val_loss: 0.4032 - val_mean_absolute_error: 78.1633 - val_mean_squared_error: 15518.0604\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.41058 to 0.40323, saving model to Weights-038--0.40323.hdf5\n",
            "Epoch 39/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4343 - mean_absolute_error: 77.3428 - mean_squared_error: 14178.5103 - val_loss: 0.6099 - val_mean_absolute_error: 89.1422 - val_mean_squared_error: 20122.4747\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.40323\n",
            "Epoch 40/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4507 - mean_absolute_error: 78.5782 - mean_squared_error: 14568.3781 - val_loss: 0.4067 - val_mean_absolute_error: 76.8317 - val_mean_squared_error: 14576.9633\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.40323\n",
            "Epoch 41/1000\n",
            "6965/6965 [==============================] - 1s 105us/step - loss: 0.4533 - mean_absolute_error: 78.9868 - mean_squared_error: 14640.6471 - val_loss: 0.3977 - val_mean_absolute_error: 77.6399 - val_mean_squared_error: 15126.4467\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.40323 to 0.39766, saving model to Weights-041--0.39766.hdf5\n",
            "Epoch 42/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4398 - mean_absolute_error: 78.6910 - mean_squared_error: 14605.5678 - val_loss: 0.4084 - val_mean_absolute_error: 77.1910 - val_mean_squared_error: 14815.8930\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.39766\n",
            "Epoch 43/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.4364 - mean_absolute_error: 77.6397 - mean_squared_error: 14490.4272 - val_loss: 0.3952 - val_mean_absolute_error: 74.1838 - val_mean_squared_error: 13099.7701\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.39766 to 0.39515, saving model to Weights-043--0.39515.hdf5\n",
            "Epoch 44/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4228 - mean_absolute_error: 77.1603 - mean_squared_error: 14034.2451 - val_loss: 0.4017 - val_mean_absolute_error: 75.3269 - val_mean_squared_error: 13191.2215\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.39515\n",
            "Epoch 45/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.4304 - mean_absolute_error: 77.9184 - mean_squared_error: 14324.5343 - val_loss: 0.3887 - val_mean_absolute_error: 76.9673 - val_mean_squared_error: 14857.3857\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.39515 to 0.38868, saving model to Weights-045--0.38868.hdf5\n",
            "Epoch 46/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4316 - mean_absolute_error: 77.9303 - mean_squared_error: 14423.8021 - val_loss: 0.4014 - val_mean_absolute_error: 73.7498 - val_mean_squared_error: 12644.6399\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.38868\n",
            "Epoch 47/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.4191 - mean_absolute_error: 77.2757 - mean_squared_error: 14221.6009 - val_loss: 0.4970 - val_mean_absolute_error: 76.5152 - val_mean_squared_error: 12909.7767\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.38868\n",
            "Epoch 48/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.4066 - mean_absolute_error: 76.7701 - mean_squared_error: 14032.6110 - val_loss: 0.3752 - val_mean_absolute_error: 75.8727 - val_mean_squared_error: 14434.7782\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.38868 to 0.37524, saving model to Weights-048--0.37524.hdf5\n",
            "Epoch 49/1000\n",
            "6965/6965 [==============================] - 1s 114us/step - loss: 0.3913 - mean_absolute_error: 74.9635 - mean_squared_error: 13415.4447 - val_loss: 0.3800 - val_mean_absolute_error: 71.7992 - val_mean_squared_error: 11365.5101\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.37524\n",
            "Epoch 50/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.3616 - mean_absolute_error: 73.6724 - mean_squared_error: 13013.4414 - val_loss: 0.3318 - val_mean_absolute_error: 71.6974 - val_mean_squared_error: 13053.1828\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.37524 to 0.33177, saving model to Weights-050--0.33177.hdf5\n",
            "Epoch 51/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.3878 - mean_absolute_error: 75.1921 - mean_squared_error: 13479.5458 - val_loss: 0.5533 - val_mean_absolute_error: 83.2247 - val_mean_squared_error: 13738.2700\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.33177\n",
            "Epoch 52/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.3660 - mean_absolute_error: 74.3513 - mean_squared_error: 13405.2573 - val_loss: 0.4214 - val_mean_absolute_error: 78.9760 - val_mean_squared_error: 12250.7250\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.33177\n",
            "Epoch 53/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.3430 - mean_absolute_error: 71.7975 - mean_squared_error: 12382.3176 - val_loss: 0.3036 - val_mean_absolute_error: 68.3049 - val_mean_squared_error: 12068.8371\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.33177 to 0.30358, saving model to Weights-053--0.30358.hdf5\n",
            "Epoch 54/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.3273 - mean_absolute_error: 69.2894 - mean_squared_error: 11455.5861 - val_loss: 0.2687 - val_mean_absolute_error: 62.6426 - val_mean_squared_error: 9638.9633\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.30358 to 0.26868, saving model to Weights-054--0.26868.hdf5\n",
            "Epoch 55/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.3385 - mean_absolute_error: 70.0785 - mean_squared_error: 11869.6248 - val_loss: 0.2792 - val_mean_absolute_error: 64.8710 - val_mean_squared_error: 10961.2205\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.26868\n",
            "Epoch 56/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.2883 - mean_absolute_error: 65.4269 - mean_squared_error: 10271.7560 - val_loss: 0.2502 - val_mean_absolute_error: 60.4654 - val_mean_squared_error: 8385.1210\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.26868 to 0.25017, saving model to Weights-056--0.25017.hdf5\n",
            "Epoch 57/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.2839 - mean_absolute_error: 65.2929 - mean_squared_error: 10143.2586 - val_loss: 0.2905 - val_mean_absolute_error: 62.8909 - val_mean_squared_error: 9008.5756\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.25017\n",
            "Epoch 58/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.2871 - mean_absolute_error: 65.4146 - mean_squared_error: 10262.0400 - val_loss: 0.2878 - val_mean_absolute_error: 65.3510 - val_mean_squared_error: 11232.5737\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.25017\n",
            "Epoch 59/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.2920 - mean_absolute_error: 65.4684 - mean_squared_error: 10431.7170 - val_loss: 0.2328 - val_mean_absolute_error: 59.4552 - val_mean_squared_error: 8568.5407\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.25017 to 0.23283, saving model to Weights-059--0.23283.hdf5\n",
            "Epoch 60/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.2684 - mean_absolute_error: 63.4112 - mean_squared_error: 9710.6637 - val_loss: 0.4203 - val_mean_absolute_error: 81.0591 - val_mean_squared_error: 16163.8592\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.23283\n",
            "Epoch 61/1000\n",
            "6965/6965 [==============================] - 1s 105us/step - loss: 0.2883 - mean_absolute_error: 64.9831 - mean_squared_error: 10220.9501 - val_loss: 0.3100 - val_mean_absolute_error: 71.2754 - val_mean_squared_error: 12628.9473\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.23283\n",
            "Epoch 62/1000\n",
            "6965/6965 [==============================] - 1s 102us/step - loss: 0.2878 - mean_absolute_error: 65.6734 - mean_squared_error: 10348.1286 - val_loss: 0.2359 - val_mean_absolute_error: 60.3306 - val_mean_squared_error: 9349.2390\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.23283\n",
            "Epoch 63/1000\n",
            "6965/6965 [==============================] - 1s 109us/step - loss: 0.2682 - mean_absolute_error: 63.4842 - mean_squared_error: 9890.8717 - val_loss: 0.2544 - val_mean_absolute_error: 63.4513 - val_mean_squared_error: 10511.5336\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.23283\n",
            "Epoch 64/1000\n",
            "6965/6965 [==============================] - 1s 106us/step - loss: 0.2609 - mean_absolute_error: 62.4256 - mean_squared_error: 9361.2080 - val_loss: 0.4057 - val_mean_absolute_error: 85.4829 - val_mean_squared_error: 14616.8187\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.23283\n",
            "Epoch 65/1000\n",
            "6965/6965 [==============================] - 1s 102us/step - loss: 0.2587 - mean_absolute_error: 62.6884 - mean_squared_error: 9554.7785 - val_loss: 0.2500 - val_mean_absolute_error: 61.6180 - val_mean_squared_error: 8338.8478\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.23283\n",
            "Epoch 66/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.2580 - mean_absolute_error: 61.8277 - mean_squared_error: 9300.6124 - val_loss: 0.2811 - val_mean_absolute_error: 66.2636 - val_mean_squared_error: 11401.9169\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.23283\n",
            "Epoch 67/1000\n",
            "6965/6965 [==============================] - 1s 108us/step - loss: 0.2506 - mean_absolute_error: 61.3865 - mean_squared_error: 9217.3803 - val_loss: 0.4348 - val_mean_absolute_error: 73.0388 - val_mean_squared_error: 10500.8979\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.23283\n",
            "Epoch 68/1000\n",
            "6965/6965 [==============================] - 1s 107us/step - loss: 0.2695 - mean_absolute_error: 63.5888 - mean_squared_error: 9800.9312 - val_loss: 0.3037 - val_mean_absolute_error: 67.4318 - val_mean_squared_error: 9616.2298\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.23283\n",
            "Epoch 69/1000\n",
            "6965/6965 [==============================] - 1s 105us/step - loss: 0.2755 - mean_absolute_error: 64.5486 - mean_squared_error: 9989.0521 - val_loss: 0.2835 - val_mean_absolute_error: 71.1826 - val_mean_squared_error: 13947.8498\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.23283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yld7jrdxg2J5",
        "outputId": "054b1a1f-b5af-43f6-932b-ce03460bb651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Save the trained model to a pickle file\n",
        "import pickle\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(NN_model,'BounceDemandPrediction_without_weather.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BounceDemandPredictionv001.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7lN0leLJEKk_",
        "colab": {}
      },
      "source": [
        "''''import pandas as pd\n",
        "lst=[mean_temp[0],mean_humidity[0],mean_windspeed[0],mean_atemp[0],sd_temp[0],sd_humidity[0],sd_windspeed[0],sd_atemp[0]]\n",
        " \n",
        "df = pd.DataFrame([lst],columns =['mean_temp', 'mean_humidity','mean_windspeed','mean_atemp','sd_temp','sd_humidity','sd_windspeed','sd_atemp']) \n",
        "df.to_csv('data_mean_std.csv',index=False)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjxqXbImhxIb",
        "colab": {}
      },
      "source": [
        "'''#Define transformation functions\n",
        "def transform_temp(temp):\n",
        "  return ((temp-mean_temp[0])/sd_temp[0])\n",
        "\n",
        "def transform_atemp(atemp):\n",
        "  return ((atemp-mean_atemp[0])/sd_atemp[0])\n",
        "\n",
        "def transform_humidity(humidity):\n",
        "  return ((humidity-mean_humidity[0])/sd_humidity[0])\n",
        "\n",
        "def transform_windspeed(windspeed):\n",
        "   return ((windspeed-mean_windspeed[0])/sd_windspeed[0])'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMswIHRZirY6",
        "colab": {}
      },
      "source": [
        "#Evaluate on test data\n",
        "\n",
        "#Drop casual and registered users columns\n",
        "test_data = drop_redundantcolumns(test_data)\n",
        "\n",
        "#Separate target variable, and convert features data into a numpy array\n",
        "test_data_x, test_data_y = create_targetvariable(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yaG78syOirhK",
        "outputId": "8e81e46b-7c99-4d70-8928-d98357ad0160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scores=NN_model.evaluate(test_data_x,test_data_y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2178/2178 [==============================] - 0s 36us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VAmOOv7nkJ17",
        "outputId": "55a1b974-db92-4545-fe1f-568b4394c4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test1_loss=scores[0]\n",
        "test1_mae=scores[1]\n",
        "test1_mse=scores[2]\n",
        "\n",
        "test1_mae\n",
        "\n",
        "#Evaluate on Test Data Complete"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.22997662778072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jqHHPciAkJ5_",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L--WIAJFkdhf",
        "colab": {}
      },
      "source": [
        "#Kaggle submission\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "test_original=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p17NxDxBkp_k",
        "colab": {}
      },
      "source": [
        "#Transform Test Data\n",
        "#Add new features of date time\n",
        "test=datetime(test)\n",
        "test=test.drop('datetime',axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2MoeVzXUmdrw",
        "colab": {}
      },
      "source": [
        "\n",
        "#Normalize weather data\n",
        "test[\"temp\"] = transform_temp(test[\"temp\"])\n",
        "test[\"atemp\"] = transform_atemp(test[\"atemp\"])\n",
        "test[\"humidity\"] = transform_humidity(test[\"humidity\"])\n",
        "test[\"windspeed\"] = transform_windspeed(test[\"windspeed\"])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0U7ceaIQolZw",
        "colab": {}
      },
      "source": [
        "\n",
        "#test, mean_temp, sd_temp=normalize(test,[\"temp\"])\n",
        "#test,mean_atemp,sd_atemp=normalize(test,[\"atemp\"])\n",
        "#test,mean_humidity,sd_humidity=normalize(test,[\"humidity\"])\n",
        "#test,mean_windspeed,sd_windspeed=normalize(test,[\"windspeed\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5IW52FNmmIL",
        "colab": {}
      },
      "source": [
        "\n",
        "#One hot-encode categorical data\n",
        "test = dummy_data(test, [\"season\",\"weather\",\"hour\",\"dayofweek\",\"month\"]) #\"day\" not included because of incomplete data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hfHI_qAPmO6k",
        "colab": {}
      },
      "source": [
        "prediction=NN_model.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1vcmvD2rnLy8",
        "outputId": "3246dd38-45ae-424e-df8b-6f5e6fb1ab59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "evaluation=test_original['datetime'].to_frame()\n",
        "evaluation[\"count\"]=prediction\n",
        "evaluation[\"count\"] = evaluation[\"count\"].astype(int)\n",
        "evaluation[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-20 00:00:00</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-20 01:00:00</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-20 02:00:00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-20 03:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-20 04:00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011-01-20 05:00:00</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2011-01-20 06:00:00</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2011-01-20 07:00:00</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2011-01-20 08:00:00</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2011-01-20 09:00:00</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  count\n",
              "0  2011-01-20 00:00:00      6\n",
              "1  2011-01-20 01:00:00      5\n",
              "2  2011-01-20 02:00:00      2\n",
              "3  2011-01-20 03:00:00      1\n",
              "4  2011-01-20 04:00:00      1\n",
              "5  2011-01-20 05:00:00      7\n",
              "6  2011-01-20 06:00:00     50\n",
              "7  2011-01-20 07:00:00    140\n",
              "8  2011-01-20 08:00:00    178\n",
              "9  2011-01-20 09:00:00     58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lpa7EWLNngP5",
        "colab": {}
      },
      "source": [
        "evaluation.to_csv(\"submission_anupam.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3FZp--YblL2f",
        "outputId": "ef88bb3b-2ec2-4a52-cbea-98eff844d0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -1.228358\n",
              "1      -1.228358\n",
              "2      -1.228358\n",
              "3      -1.228358\n",
              "4      -1.228358\n",
              "5      -1.333599\n",
              "6      -1.438841\n",
              "7      -1.438841\n",
              "8      -1.438841\n",
              "9      -1.333599\n",
              "10     -1.228358\n",
              "11     -1.123116\n",
              "12     -1.017874\n",
              "13     -1.123116\n",
              "14     -1.017874\n",
              "15     -0.912633\n",
              "16     -1.017874\n",
              "17     -1.017874\n",
              "18     -1.228358\n",
              "19     -1.228358\n",
              "20     -1.228358\n",
              "21     -1.333599\n",
              "22     -1.333599\n",
              "23     -1.333599\n",
              "24     -1.333599\n",
              "25     -1.333599\n",
              "26     -1.333599\n",
              "27     -1.438841\n",
              "28     -1.438841\n",
              "29     -1.333599\n",
              "          ...   \n",
              "6463   -1.333599\n",
              "6464   -0.807391\n",
              "6465   -1.438841\n",
              "6466   -1.544083\n",
              "6467   -1.544083\n",
              "6468   -1.544083\n",
              "6469   -1.649324\n",
              "6470   -1.649324\n",
              "6471   -1.754566\n",
              "6472   -1.754566\n",
              "6473   -1.859808\n",
              "6474   -1.754566\n",
              "6475   -1.754566\n",
              "6476   -1.754566\n",
              "6477   -1.859808\n",
              "6478   -1.649324\n",
              "6479   -1.544083\n",
              "6480   -1.438841\n",
              "6481   -1.333599\n",
              "6482   -1.228358\n",
              "6483   -1.123116\n",
              "6484   -1.123116\n",
              "6485   -1.228358\n",
              "6486   -1.228358\n",
              "6487   -1.228358\n",
              "6488   -1.228358\n",
              "6489   -1.228358\n",
              "6490   -1.228358\n",
              "6491   -1.228358\n",
              "6492   -1.228358\n",
              "Name: temp, Length: 6493, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-xtDn0VbkRV",
        "colab": {}
      },
      "source": [
        "\n",
        "#For debugging only\n",
        "#print(mean_temp, sd_temp, mean_atemp, sd_atemp, mean_humidity, sd_humidity, mean_windspeed, sd_windspeed)\n",
        "print(data_x[0:2])\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V30RCC7xdBjW",
        "colab": {}
      },
      "source": [
        "#For debugging only\n",
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}